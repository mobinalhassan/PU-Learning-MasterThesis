{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# import tensorflow_probability as tfp\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from uitils import *\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_recall_curve, auc, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced training set shape: (5000, 28, 28)\n",
      "Reduced testing set shape: (1000, 28, 28)\n",
      "Training labels distribution: [2545 1000]\n",
      "Training original labels distribution: [2545 1000]\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, y_train = extract_samples(x_train, y_train, 500)\n",
    "x_test, y_test = extract_samples(x_test, y_test, 100)\n",
    "print(\"Reduced training set shape:\", x_train.shape)\n",
    "print(\"Reduced testing set shape:\", x_test.shape)\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "y_train = y_train % 2  # Convert labels to 0 (even) and 1 (odd) \n",
    "y_test = y_test % 2\n",
    "s=y_train\n",
    "\n",
    "# Initialize 's' to zeros, meaning initially all are unlabeled\n",
    "s = np.zeros_like(y_train)\n",
    "\n",
    "# Select a random 300 samples where y_train == 1 to be labeled\n",
    "positive_indices = np.where(y_train == 1)[0]\n",
    "chosen_indices = np.random.choice(positive_indices, size=1000, replace=False)\n",
    "\n",
    "# Mark these as labeled in 's'\n",
    "s[chosen_indices] = 1\n",
    "\n",
    "# Mark the rest of the positive_indices except the chosen 300 as potential targets for unlabeled marking\n",
    "rest_of_positives = np.setdiff1d(positive_indices, chosen_indices)\n",
    "\n",
    "# From the rest, select 30% and mark their labels as 0 in y_train\n",
    "number_to_mark_unlabeled = int(len(rest_of_positives) * 0.03)\n",
    "# number_to_mark_unlabeled = int(1)\n",
    "unlabeled_indices = np.random.choice(rest_of_positives, size=number_to_mark_unlabeled, replace=False)\n",
    "y_train[unlabeled_indices] = 0\n",
    "\n",
    "# Remove the rest of the positive rows that are not in the chosen 300 and not marked as unlabeled\n",
    "indices_to_drop = np.setdiff1d(rest_of_positives, np.concatenate([chosen_indices, unlabeled_indices]))\n",
    "x_train = np.delete(x_train, indices_to_drop, axis=0)\n",
    "y_train = np.delete(y_train, indices_to_drop)\n",
    "s = np.delete(s, indices_to_drop)\n",
    "\n",
    "print(\"Training labels distribution:\", np.bincount(y_train))\n",
    "print(\"Training original labels distribution:\", np.bincount(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_pu_datasets(x, y, n_labeled, pos_fraction):\n",
    "#     # Select a random 300 rows where y_train == 1\n",
    "#     positive_indices = np.where(y_train == 1)[0]\n",
    "#     chosen_indices = np.random.choice(positive_indices, size=n_labeled, replace=False)\n",
    "\n",
    "#     # Mark the rest of the positive_indices except the chosen 300 as potential targets for unlabeled marking\n",
    "#     rest_of_positives = np.setdiff1d(positive_indices, chosen_indices)\n",
    "\n",
    "#     # From the rest, select 30% and mark their labels as 0\n",
    "#     number_to_mark_unlabeled = int(len(rest_of_positives) * pos_fraction)\n",
    "#     unlabeled_indices = np.random.choice(rest_of_positives, size=number_to_mark_unlabeled, replace=False)\n",
    "#     y_train[unlabeled_indices] = 0\n",
    "\n",
    "#     # Remove the rest of the rows where y=1 that are not in the chosen 300\n",
    "#     indices_to_drop = np.setdiff1d(rest_of_positives, unlabeled_indices)\n",
    "#     x_train = np.delete(x_train, indices_to_drop, axis=0)\n",
    "#     y_train = np.delete(y_train, indices_to_drop)\n",
    "\n",
    "#     return x_train, y_train\n",
    "\n",
    "# # Create datasets as per specifications from the paper\n",
    "# # configs = [(300, 0.3), (500, 0.5), (1000, 0.7)]\n",
    "# configs = [(300, 0.3)]\n",
    "# datasets = [create_pu_datasets(x_train, y_train, n, frac) for n, frac in configs]\n",
    "\n",
    "# for i, (train_x_pu, train_y_pu) in enumerate(datasets):\n",
    "#     print(f\"Configuration {i+1} label distribution: {np.bincount(train_y_pu.astype(int))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "23/23 [==============================] - 57s 1s/step - loss: 349.2628 - accuracy: 0.4475 - val_loss: 346.5315 - val_accuracy: 0.5458\n",
      "Epoch 2/15\n",
      "23/23 [==============================] - 16s 730ms/step - loss: 344.2337 - accuracy: 0.6439 - val_loss: 341.6066 - val_accuracy: 0.5430\n",
      "Epoch 3/15\n",
      "23/23 [==============================] - 20s 722ms/step - loss: 339.3407 - accuracy: 0.7147 - val_loss: 336.8028 - val_accuracy: 0.5261\n",
      "Epoch 4/15\n",
      "23/23 [==============================] - 16s 729ms/step - loss: 334.5699 - accuracy: 0.7567 - val_loss: 332.1226 - val_accuracy: 0.5515\n",
      "Epoch 5/15\n",
      "23/23 [==============================] - 16s 718ms/step - loss: 329.9194 - accuracy: 0.7821 - val_loss: 327.5630 - val_accuracy: 0.5472\n",
      "Epoch 6/15\n",
      "23/23 [==============================] - 16s 723ms/step - loss: 325.3863 - accuracy: 0.7980 - val_loss: 323.1222 - val_accuracy: 0.5430\n",
      "Epoch 7/15\n",
      "23/23 [==============================] - 16s 717ms/step - loss: 320.9694 - accuracy: 0.8078 - val_loss: 318.7935 - val_accuracy: 0.5402\n",
      "Epoch 8/15\n",
      "23/23 [==============================] - 20s 721ms/step - loss: 316.6659 - accuracy: 0.8202 - val_loss: 314.5724 - val_accuracy: 0.5388\n",
      "Epoch 9/15\n",
      "23/23 [==============================] - 16s 706ms/step - loss: 312.4714 - accuracy: 0.8332 - val_loss: 310.4598 - val_accuracy: 0.4838\n",
      "Epoch 10/15\n",
      "23/23 [==============================] - 16s 724ms/step - loss: 308.3820 - accuracy: 0.8477 - val_loss: 306.4467 - val_accuracy: 0.4697\n",
      "Epoch 11/15\n",
      "23/23 [==============================] - 20s 714ms/step - loss: 304.3943 - accuracy: 0.8664 - val_loss: 302.5355 - val_accuracy: 0.4316\n",
      "Epoch 12/15\n",
      "23/23 [==============================] - 16s 696ms/step - loss: 300.5042 - accuracy: 0.8826 - val_loss: 298.7175 - val_accuracy: 0.4133\n",
      "Epoch 13/15\n",
      "23/23 [==============================] - 16s 716ms/step - loss: 296.7096 - accuracy: 0.8907 - val_loss: 294.9932 - val_accuracy: 0.3808\n",
      "Epoch 14/15\n",
      "23/23 [==============================] - 16s 709ms/step - loss: 293.0064 - accuracy: 0.9002 - val_loss: 291.3569 - val_accuracy: 0.3625\n",
      "Epoch 15/15\n",
      "23/23 [==============================] - 16s 514ms/step - loss: 289.3929 - accuracy: 0.9055 - val_loss: 287.7986 - val_accuracy: 0.4048\n"
     ]
    }
   ],
   "source": [
    "weight_decay = 2.0\n",
    "model_1 = Sequential([\n",
    "    Conv2D(128, (3, 3), padding='same', input_shape=(28, 28, 1), kernel_regularizer=l2(weight_decay)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Conv2D(32, (1, 1), padding='same', kernel_regularizer=l2(weight_decay)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Flatten(),\n",
    "    Dense(16, kernel_regularizer=l2(weight_decay)),\n",
    "    Activation('relu'),\n",
    "    Dense(10, kernel_regularizer=l2(weight_decay)),\n",
    "    Activation('relu'),\n",
    "    Dense(1, kernel_regularizer=l2(weight_decay)),\n",
    "    Activation('sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "model_1.compile(optimizer=Adam(learning_rate=0.00001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history_1 = model_1.fit(x_train, y_train, epochs=15, batch_size=128, validation_split=0.2)\n",
    "# model_1.save_weights('clf_model_.weights.h5')\n",
    "# model_1.load_weights('clf_model_.weights.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probablistic outcome of classifer to pre-train policy network\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 11s 94ms/step\n",
      "Threshold: [0.44182795]\n",
      "Classifer predicted labels distribution: [  62 3483]\n"
     ]
    }
   ],
   "source": [
    "probabilities = model_1.predict(x_train)\n",
    "threshold = min(probabilities[y_train == 1])\n",
    "print(f\"Threshold: {threshold}\")\n",
    "# Convert probabilities to binary labels based on the threshold\n",
    "predicted_labels = (probabilities >= threshold).astype(int)\n",
    "clf_predicted_labels = predicted_labels.flatten().astype(int)\n",
    "\n",
    "print(\"Classifer predicted labels distribution:\", np.bincount(clf_predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 5s 154ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(list(probabilities))\n",
    "\n",
    "# Predictions from the second classifier\n",
    "predictions = model_1.predict(x_test)\n",
    "predicted_classes = (predictions > 0.5).astype(int).flatten()  # Assuming binary classification\n",
    "\n",
    "# Selecting a few images to display\n",
    "indices = np.random.choice(range(len(x_test)), 25, replace=False)  # Randomly select 25 images\n",
    "selected_images = x_test[indices]\n",
    "selected_labels = y_test[indices]\n",
    "selected_predictions = predicted_classes[indices]\n",
    "\n",
    "# Plotting\n",
    "plot_images(selected_images, selected_labels, selected_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(list(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "23/23 [==============================] - 26s 723ms/step - loss: 145.8770 - accuracy: 0.9446 - val_loss: 142.3364 - val_accuracy: 0.9986\n",
      "Epoch 2/5\n",
      "23/23 [==============================] - 11s 495ms/step - loss: 139.4155 - accuracy: 0.9785 - val_loss: 136.0515 - val_accuracy: 0.9986\n",
      "Epoch 3/5\n",
      "23/23 [==============================] - 15s 674ms/step - loss: 133.2929 - accuracy: 0.9785 - val_loss: 130.1075 - val_accuracy: 0.9986\n",
      "Epoch 4/5\n",
      "23/23 [==============================] - 11s 486ms/step - loss: 127.5066 - accuracy: 0.9785 - val_loss: 124.4918 - val_accuracy: 0.9986\n",
      "Epoch 5/5\n",
      "23/23 [==============================] - 15s 680ms/step - loss: 122.0401 - accuracy: 0.9785 - val_loss: 119.1858 - val_accuracy: 0.9986\n"
     ]
    }
   ],
   "source": [
    "# Policy-Network Model\n",
    "\n",
    "class PolicyGradientNetwork:\n",
    "    def __init__(self):\n",
    "        self.model = self._create_model()\n",
    "    \n",
    "    def _create_model(self):\n",
    "        weight_decay = 0.5\n",
    "        model = Sequential([\n",
    "            Conv2D(96, (3, 3), padding='same', input_shape=(28, 28, 1), kernel_regularizer=l2(weight_decay)),\n",
    "            Activation('relu'),\n",
    "            Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)),\n",
    "            Activation('relu'),\n",
    "            Flatten(),\n",
    "            Dense(100, kernel_regularizer=l2(weight_decay)),\n",
    "            Activation('relu'),\n",
    "            Dense(10, kernel_regularizer=l2(weight_decay)),  # Additional Dense layer\n",
    "            Activation('relu'),\n",
    "            Dense(1, kernel_regularizer=l2(weight_decay)),  # Softmax output for binary classification\n",
    "            Activation('sigmoid') # Hard labeling\n",
    "        ])\n",
    "        return model\n",
    "    \n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "    \n",
    "\n",
    "policy_network = PolicyGradientNetwork()\n",
    "pn_model = policy_network.get_model()\n",
    "\n",
    "pn_model.compile(optimizer=Adam(learning_rate=0.00001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_2 = pn_model.fit(x_train, clf_predicted_labels, epochs=5, batch_size=128, validation_split=0.2)\n",
    "# pn_model.save_weights('pn_model_.weights.h5')\n",
    "# pn_model.load_weights('pn_model_.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 10s 91ms/step\n",
      "Threshold: [0.54608524]\n",
      "Classifer predicted labels distribution: [   0 3545]\n"
     ]
    }
   ],
   "source": [
    "probabilities = pn_model.predict(x_train)\n",
    "threshold = min(probabilities[y_train == 1])\n",
    "print(f\"Threshold: {threshold}\")\n",
    "# Convert probabilities to binary labels based on the threshold\n",
    "predicted_labels = (probabilities >= threshold).astype(int)\n",
    "np_predicted_labels = predicted_labels.flatten().astype(int)\n",
    "\n",
    "print(\"Classifer predicted labels distribution:\", np.bincount(np_predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, model, target_model, alpha=0.00001, gamma=0.99):\n",
    "        self.gamma = gamma  # Discount factor\n",
    "        self.lr = alpha  # Learning rate\n",
    "        self.model = model  # Policy model\n",
    "        self.target_model = target_model # target policy model\n",
    "        self.state_memory = []\n",
    "        self.action_memory = []\n",
    "        self.reward_memory = []\n",
    "\n",
    "    def choose_action(self, states, s, threshold=0.5):\n",
    "        # Convert states to float32 tensor within the function\n",
    "        states = tf.convert_to_tensor(states, dtype=tf.float32)\n",
    "        probabilities = self.target_model(states)  # Make sure target model expects float32 input\n",
    "        # action_sampler = tfp.distributions.Bernoulli(probs=probabilities, dtype=tf.float32)\n",
    "        # actions = action_sampler.sample()\n",
    "        # print(f\"probabilities ={probabilities}\")\n",
    "        # actions = tf.cast(tf.random.uniform(tf.shape(probabilities)) < probabilities, tf.int32)\n",
    "\n",
    "        inferred_labels = tf.cast(probabilities > threshold, tf.int32)       \n",
    "        s = tf.reshape(s, tf.shape(inferred_labels))  # Ensuring s is the same shape as inferred_labels\n",
    "        actions = tf.where(s == 1, 1, inferred_labels)\n",
    "        actions = tf.squeeze(actions)  # This should correctly squeeze actions to shape (128,)\n",
    "        return actions.numpy(), probabilities.numpy()\n",
    "\n",
    "\n",
    "    def store_transition(self, states, actions, rewards):\n",
    "        self.state_memory.extend(states)\n",
    "        self.action_memory.extend(actions)\n",
    "        self.reward_memory.extend(rewards)\n",
    "\n",
    "    def learn(self):\n",
    "        actions = np.array(self.action_memory)\n",
    "        rewards = np.array(self.reward_memory)\n",
    "        states = np.array(self.state_memory)\n",
    "\n",
    "        # Calculate discounted rewards\n",
    "        G = np.zeros_like(rewards)\n",
    "        for t in range(len(rewards)):\n",
    "            G_sum = 0\n",
    "            discount = 1\n",
    "            for k in range(t, len(rewards)):\n",
    "                G_sum += rewards[k] * discount\n",
    "                discount *= self.gamma\n",
    "            G[t] = G_sum\n",
    "\n",
    "        # Updating policy\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = 0\n",
    "            for idx, (g, state) in enumerate(zip(G, states)):\n",
    "                state = tf.convert_to_tensor([state], dtype=tf.float32)\n",
    "                probs = self.model(state, training=True)\n",
    "                # action_probs = tfp.distributions.Bernoulli(probs=probs)\n",
    "                # log_prob = action_probs.log_prob(actions[idx])\n",
    "                # loss += -g * tf.reduce_sum(log_prob)\n",
    "                action_probs = tf.where(actions[idx] == 1, probs, 1 - probs)\n",
    "                log_prob = tf.math.log(action_probs)\n",
    "                loss += -g * tf.reduce_sum(log_prob)\n",
    "\n",
    "        gradients = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.model.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
    "\n",
    "        # Clear memory\n",
    "        self.state_memory = []\n",
    "        self.action_memory = []\n",
    "        self.reward_memory = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone policy model for stable target policy\n",
    "target_policy_model = tf.keras.models.clone_model(pn_model)\n",
    "target_policy_model.compile(optimizer=Adam(learning_rate=0.00001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = {\n",
    "    'epoch_loss': [],\n",
    "    'epoch_accuracy': [],\n",
    "    'batch_loss': [],\n",
    "    'batch_accuracy': [],\n",
    "    'predictions': [],\n",
    "    'rewards': [],\n",
    "    'thresholds': [],\n",
    "    'ROC_AUC': [],\n",
    "    'accuracy':[],\n",
    "    'PR_AUC':[],\n",
    "    'recall':[],\n",
    "    'f1':[]\n",
    "}\n",
    "agent = Agent(pn_model,target_model=target_policy_model, alpha=0.00001, gamma=0.99)\n",
    "# Example parameters\n",
    "n_epochs = 300\n",
    "n_epochs = 10\n",
    "batch_size = 128 # You can adjust the batch size as needed\n",
    "\n",
    "def shuffle_data(x_train, y_train, s):\n",
    "    indices = np.arange(len(x_train))\n",
    "    np.random.shuffle(indices)\n",
    "    return x_train[indices], y_train[indices], s[indices]\n",
    "\n",
    "def create_mini_batches(x_train, y_train, s, batch_size):\n",
    "    for start_idx in range(0, len(x_train) - batch_size + 1, batch_size):\n",
    "        excerpt = slice(start_idx, start_idx + batch_size)\n",
    "        yield x_train[excerpt], y_train[excerpt], s[excerpt]\n",
    "\n",
    "def calculate_threshold(clf_probabilities, y_batch):\n",
    "    # Identify indices of positive examples\n",
    "    positive_indices = (y_batch == 1)\n",
    "    \n",
    "    # Calculate threshmin from positive examples\n",
    "    if np.any(positive_indices):\n",
    "        threshmin = np.min(clf_probabilities[positive_indices])\n",
    "    else:\n",
    "        threshmin = 0  # Default value if no positive examples are present\n",
    "\n",
    "    # Identify U0 - samples with predictions >= threshmin\n",
    "    U0_indices = (clf_probabilities >= threshmin)\n",
    "    \n",
    "    # Calculate the final threshold using Equation 5\n",
    "    if np.any(U0_indices):\n",
    "        threshold = np.mean(clf_probabilities[U0_indices])\n",
    "    else:\n",
    "        threshold = threshmin  # Use threshmin if no samples meet the U0 criteria\n",
    "\n",
    "    return threshold\n",
    "\n",
    "def calculate_rewards(clf_probabilities, y_batch, threshold):\n",
    "    # Reward calculation needs to consider whether predictions meet a certain threshold\n",
    "    # Positive examples above threshold or negative examples below threshold get positive rewards\n",
    "    rewards = []\n",
    "    for prob, actual in zip(clf_probabilities.flatten(), y_batch):\n",
    "        if actual == 1 or (actual == 0 and prob >= threshold):\n",
    "            reward = prob  # Reward is the probability itself if conditions are met\n",
    "        else:\n",
    "            reward = prob -1  # Otherwise, reward is the complement of the probability\n",
    "        rewards.append(reward)\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "4/4 [==============================] - 0s 26ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 24ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 24ms/step\n",
      "4/4 [==============================] - 0s 28ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 4s 1s/step\n",
      "4/4 [==============================] - 0s 24ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 30ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 30ms/step\n",
      "4/4 [==============================] - 0s 23ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 27ms/step\n",
      "4/4 [==============================] - 4s 14ms/step\n",
      "4/4 [==============================] - 4s 13ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 24ms/step\n",
      "3/3 [==============================] - 0s 23ms/step\n",
      "Epoch 1: Loss = 285.51869310651506, Accuracy = 0.8176460681217057\n",
      "32/32 [==============================] - 5s 152ms/step\n",
      "ROC AUC Score: 0.8613839999999999\n",
      "Accuracy Score: 0.685\n",
      "Precision-Recall AUC: 0.8547282811277249\n",
      "Recall: 0.956\n",
      "F1 Score: 0.7521636506687648\n",
      "Updating target policy...\n",
      "Epoch 2/300\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 4s 1s/step\n",
      "4/4 [==============================] - 0s 24ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 27ms/step\n",
      "4/4 [==============================] - 0s 23ms/step\n",
      "4/4 [==============================] - 0s 29ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 24ms/step\n",
      "4/4 [==============================] - 0s 28ms/step\n",
      "4/4 [==============================] - 4s 1s/step\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "4/4 [==============================] - 0s 21ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 21ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 21ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 19ms/step\n",
      "4/4 [==============================] - 0s 21ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "3/3 [==============================] - 0s 12ms/step\n",
      "Epoch 2: Loss = 281.478513445173, Accuracy = 0.7038949307586465\n",
      "32/32 [==============================] - 0s 13ms/step\n",
      "ROC AUC Score: 0.7165600000000001\n",
      "Accuracy Score: 0.5\n",
      "Precision-Recall AUC: 0.7079644439830854\n",
      "Recall: 1.0\n",
      "F1 Score: 0.6666666666666666\n",
      "Epoch 3/300\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "4/4 [==============================] - 0s 23ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 24ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "Epoch 3: Loss = 277.02569580078125, Accuracy = 0.9381583482027054\n",
      "32/32 [==============================] - 1s 16ms/step\n",
      "ROC AUC Score: 0.630012\n",
      "Accuracy Score: 0.5\n",
      "Precision-Recall AUC: 0.6168829688982154\n",
      "Recall: 1.0\n",
      "F1 Score: 0.6666666666666666\n",
      "Epoch 4/300\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "4/4 [==============================] - 0s 21ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "4/4 [==============================] - 0s 21ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "Epoch 4: Loss = 273.15121786934986, Accuracy = 0.9081548026629856\n",
      "32/32 [==============================] - 0s 10ms/step\n",
      "ROC AUC Score: 0.567612\n",
      "Accuracy Score: 0.5\n",
      "Precision-Recall AUC: 0.5526866719770362\n",
      "Recall: 1.0\n",
      "F1 Score: 0.6666666666666666\n",
      "Updating target policy...\n",
      "Epoch 5/300\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 21ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 26ms/step\n",
      "4/4 [==============================] - 0s 21ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "3/3 [==============================] - 0s 10ms/step\n",
      "Epoch 5: Loss = 269.15722002301897, Accuracy = 0.9908963526998248\n",
      "32/32 [==============================] - 0s 10ms/step\n",
      "ROC AUC Score: 0.500376\n",
      "Accuracy Score: 0.5\n",
      "Precision-Recall AUC: 0.5002344337804814\n",
      "Recall: 1.0\n",
      "F1 Score: 0.6666666666666666\n",
      "Epoch 6/300\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 21ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 21ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "3/3 [==============================] - 0s 24ms/step\n",
      "Epoch 6: Loss = 265.5091661725725, Accuracy = 0.9541760236024857\n",
      "32/32 [==============================] - 0s 13ms/step\n",
      "ROC AUC Score: 0.475558\n",
      "Accuracy Score: 0.5\n",
      "Precision-Recall AUC: 0.48009791543659996\n",
      "Recall: 1.0\n",
      "F1 Score: 0.6666666666666666\n",
      "Epoch 7/300\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 27ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "Epoch 7: Loss = 261.8798086983817, Accuracy = 0.957174403326852\n",
      "32/32 [==============================] - 0s 13ms/step\n",
      "ROC AUC Score: 0.45702200000000004\n",
      "Accuracy Score: 0.5\n",
      "Precision-Recall AUC: 0.4659681462180706\n",
      "Recall: 1.0\n",
      "F1 Score: 0.6666666666666666\n",
      "Updating target policy...\n",
      "Epoch 8/300\n",
      "4/4 [==============================] - 0s 26ms/step\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 21ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "4/4 [==============================] - 0s 24ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "3/3 [==============================] - 0s 11ms/step\n",
      "Epoch 8: Loss = 258.29348645891463, Accuracy = 0.9858858947243009\n",
      "32/32 [==============================] - 0s 12ms/step\n",
      "ROC AUC Score: 0.432372\n",
      "Accuracy Score: 0.5\n",
      "Precision-Recall AUC: 0.45038786438488204\n",
      "Recall: 1.0\n",
      "F1 Score: 0.6666666666666666\n",
      "Epoch 9/300\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 22ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "3/3 [==============================] - 0s 12ms/step\n",
      "Epoch 9: Loss = 254.89352253505163, Accuracy = 0.9702824630907604\n",
      "32/32 [==============================] - 0s 13ms/step\n",
      "ROC AUC Score: 0.417628\n",
      "Accuracy Score: 0.5\n",
      "Precision-Recall AUC: 0.4409429288648399\n",
      "Recall: 1.0\n",
      "F1 Score: 0.6666666666666666\n",
      "Epoch 10/300\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 19ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 21ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 21ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "3/3 [==============================] - 0s 24ms/step\n",
      "Epoch 10: Loss = 251.5638062613351, Accuracy = 0.9638270714453289\n",
      "32/32 [==============================] - 1s 16ms/step\n",
      "ROC AUC Score: 0.405456\n",
      "Accuracy Score: 0.5\n",
      "Precision-Recall AUC: 0.43265964979770066\n",
      "Recall: 1.0\n",
      "F1 Score: 0.6666666666666666\n",
      "Updating target policy...\n",
      "Epoch 11/300\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 19ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 16ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 26ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "Epoch 11: Loss = 248.31035668509347, Accuracy = 0.9594281251941409\n",
      "32/32 [==============================] - 1s 16ms/step\n",
      "ROC AUC Score: 0.398128\n",
      "Accuracy Score: 0.5\n",
      "Precision-Recall AUC: 0.4276586953956863\n",
      "Recall: 1.0\n",
      "F1 Score: 0.6666666666666666\n",
      "Epoch 12/300\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 24ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 19ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 26ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "3/3 [==============================] - 0s 12ms/step\n",
      "Epoch 12: Loss = 245.12941251482283, Accuracy = 0.9583777040243149\n",
      "32/32 [==============================] - 0s 13ms/step\n",
      "ROC AUC Score: 0.391112\n",
      "Accuracy Score: 0.5\n",
      "Precision-Recall AUC: 0.42264342776165414\n",
      "Recall: 1.0\n",
      "F1 Score: 0.6666666666666666\n",
      "Epoch 13/300\n",
      "4/4 [==============================] - 0s 18ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 19ms/step\n",
      "4/4 [==============================] - 0s 24ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "Epoch 13: Loss = 242.03587504795618, Accuracy = 0.9538258888891765\n",
      "32/32 [==============================] - 1s 16ms/step\n",
      "ROC AUC Score: 0.38424\n",
      "Accuracy Score: 0.5\n",
      "Precision-Recall AUC: 0.41830427475630894\n",
      "Recall: 1.0\n",
      "F1 Score: 0.6666666666666666\n",
      "Updating target policy...\n",
      "Epoch 14/300\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 24ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "Epoch 14: Loss = 239.0958469935826, Accuracy = 0.9139986889702933\n",
      "32/32 [==============================] - 0s 13ms/step\n",
      "ROC AUC Score: 0.39591999999999994\n",
      "Accuracy Score: 0.5\n",
      "Precision-Recall AUC: 0.42201203674304383\n",
      "Recall: 1.0\n",
      "F1 Score: 0.6666666666666666\n",
      "Epoch 15/300\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "Epoch 15: Loss = 236.11614281790597, Accuracy = 0.9211987512452262\n",
      "32/32 [==============================] - 0s 9ms/step\n",
      "ROC AUC Score: 0.391012\n",
      "Accuracy Score: 0.5\n",
      "Precision-Recall AUC: 0.41814548752615316\n",
      "Recall: 1.0\n",
      "F1 Score: 0.6666666666666666\n",
      "Epoch 16/300\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 19ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 26ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 28ms/step\n",
      "4/4 [==============================] - 4s 12ms/step\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "4/4 [==============================] - 0s 23ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 4s 13ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 30ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 4s 1s/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 24ms/step\n",
      "3/3 [==============================] - 0s 13ms/step\n",
      "Epoch 16: Loss = 233.23528235299247, Accuracy = 0.915946656039783\n",
      "32/32 [==============================] - 1s 17ms/step\n",
      "ROC AUC Score: 0.39493199999999995\n",
      "Accuracy Score: 0.5\n",
      "Precision-Recall AUC: 0.41862078072167813\n",
      "Recall: 1.0\n",
      "F1 Score: 0.6666666666666666\n",
      "Updating target policy...\n",
      "Epoch 17/300\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 24ms/step\n",
      "4/4 [==============================] - 0s 27ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 23ms/step\n",
      "4/4 [==============================] - 0s 27ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 21ms/step\n",
      "4/4 [==============================] - 0s 26ms/step\n",
      "4/4 [==============================] - 4s 13ms/step\n",
      "4/4 [==============================] - 4s 12ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 14ms/step\n",
      "4/4 [==============================] - 4s 1s/step\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 27ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 24ms/step\n",
      "4/4 [==============================] - 0s 15ms/step\n",
      "4/4 [==============================] - 4s 1s/step\n",
      "4/4 [==============================] - 0s 27ms/step\n",
      "3/3 [==============================] - 4s 11ms/step\n",
      "Epoch 17: Loss = 230.4979842049735, Accuracy = 0.8755276714052472\n",
      "32/32 [==============================] - 5s 154ms/step\n",
      "ROC AUC Score: 0.437468\n",
      "Accuracy Score: 0.51\n",
      "Precision-Recall AUC: 0.4357468222463765\n",
      "Recall: 1.0\n",
      "F1 Score: 0.6711409395973155\n",
      "Epoch 18/300\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "4/4 [==============================] - 4s 13ms/step\n",
      "4/4 [==============================] - 4s 1s/step\n",
      "4/4 [==============================] - 0s 28ms/step\n",
      "4/4 [==============================] - 0s 24ms/step\n",
      "4/4 [==============================] - 0s 14ms/step\n",
      "4/4 [==============================] - 0s 28ms/step\n",
      "4/4 [==============================] - 4s 13ms/step\n",
      "4/4 [==============================] - 0s 28ms/step\n",
      "4/4 [==============================] - 0s 23ms/step\n",
      "4/4 [==============================] - 0s 24ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 4s 1s/step\n",
      "4/4 [==============================] - 0s 23ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 27ms/step\n",
      "4/4 [==============================] - 0s 24ms/step\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "3/3 [==============================] - 0s 13ms/step\n",
      "Epoch 18: Loss = 227.72480937412806, Accuracy = 0.8873436621257237\n",
      "32/32 [==============================] - 1s 14ms/step\n",
      "ROC AUC Score: 0.453144\n",
      "Accuracy Score: 0.521\n",
      "Precision-Recall AUC: 0.4419799529089371\n",
      "Recall: 1.0\n",
      "F1 Score: 0.676132521974307\n",
      "Epoch 19/300\n",
      "4/4 [==============================] - 0s 23ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 24ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 27ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 4s 1s/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 24ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 4s 1s/step\n",
      "4/4 [==============================] - 0s 24ms/step\n",
      "4/4 [==============================] - 0s 23ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "4/4 [==============================] - 0s 30ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 4s 13ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "3/3 [==============================] - 0s 14ms/step\n",
      "Epoch 19: Loss = 225.02878843035018, Accuracy = 0.9027942057166781\n",
      "32/32 [==============================] - 5s 15ms/step\n",
      "ROC AUC Score: 0.46641600000000005\n",
      "Accuracy Score: 0.526\n",
      "Precision-Recall AUC: 0.4473714494030631\n",
      "Recall: 1.0\n",
      "F1 Score: 0.6784260515603799\n",
      "Updating target policy...\n",
      "Epoch 20/300\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 24ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 4s 11ms/step\n",
      "4/4 [==============================] - 4s 1s/step\n",
      "4/4 [==============================] - 4s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 24ms/step\n",
      "4/4 [==============================] - 0s 14ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 22ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 30ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 24ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "3/3 [==============================] - 0s 12ms/step\n",
      "Epoch 20: Loss = 222.46393203735352, Accuracy = 0.8810855214084897\n",
      "32/32 [==============================] - 5s 150ms/step\n",
      "ROC AUC Score: 0.526788\n",
      "Accuracy Score: 0.568\n",
      "Precision-Recall AUC: 0.47975681177613355\n",
      "Recall: 0.99\n",
      "F1 Score: 0.6962025316455697\n",
      "Epoch 21/300\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 23ms/step\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 4s 12ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 27ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 4s 13ms/step\n",
      "4/4 [==============================] - 4s 1s/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 4s 1s/step\n",
      "4/4 [==============================] - 4s 1s/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 4s 1s/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 16ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "3/3 [==============================] - 0s 28ms/step\n",
      "Epoch 21: Loss = 219.8775896344866, Accuracy = 0.9071487677948815\n",
      "32/32 [==============================] - 5s 147ms/step\n",
      "ROC AUC Score: 0.5513739999999999\n",
      "Accuracy Score: 0.598\n",
      "Precision-Recall AUC: 0.4932633550313886\n",
      "Recall: 0.99\n",
      "F1 Score: 0.7112068965517241\n",
      "Epoch 22/300\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 4s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 4s 1s/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 4s 1s/step\n",
      "4/4 [==============================] - 0s 24ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 27ms/step\n",
      "4/4 [==============================] - 0s 24ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 24ms/step\n",
      "4/4 [==============================] - 4s 1s/step\n",
      "4/4 [==============================] - 0s 14ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 4s 12ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 4s 13ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "3/3 [==============================] - 0s 14ms/step\n",
      "Epoch 22: Loss = 217.35934611729212, Accuracy = 0.9274125014032636\n",
      "32/32 [==============================] - 1s 19ms/step\n",
      "ROC AUC Score: 0.561488\n",
      "Accuracy Score: 0.605\n",
      "Precision-Recall AUC: 0.4986139986061913\n",
      "Recall: 0.994\n",
      "F1 Score: 0.7156227501799856\n",
      "Updating target policy...\n",
      "Epoch 23/300\n",
      "4/4 [==============================] - 0s 28ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 27ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 24ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 23ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 4s 11ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 24ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 24ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "def train_model(x_train, y_train, s, epochs=300, batch_size=128, min_delta=0.0001, patience=10):\n",
    "    x_train = x_train.astype('float32')\n",
    "    y_train = y_train.astype('float32')\n",
    "    s = s.astype('float32')\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train, s))\n",
    "    dataset = dataset.shuffle(buffer_size=len(x_train)).batch(batch_size)\n",
    "\n",
    "    # early_stopping = EarlyStopping(monitor='val_accuracy', patience=patience, min_delta=min_delta, mode='max', restore_best_weights=True, verbose=1)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        epoch_loss = 0\n",
    "        epoch_accuracy = 0\n",
    "        batch_count = 0\n",
    "        # first_iteration = True\n",
    "        # threshold_pass = 0.5\n",
    "        threshold = 0.5\n",
    "        for x_batch, y_batch, s_batch in dataset:\n",
    "            # Get actions and probabilities for the entire batch\n",
    "            actions, probabilities = agent.choose_action(x_batch, s_batch, threshold=threshold)\n",
    "\n",
    "            # Fit the model on the current batch and update history\n",
    "            batch_history = model_1.fit(x_batch, actions, epochs=1, batch_size=len(x_batch), validation_split=0.2, verbose=0)\n",
    "            history['batch_loss'].append(batch_history.history['loss'][0])\n",
    "            history['batch_accuracy'].append(batch_history.history['accuracy'][0])\n",
    "            epoch_loss += batch_history.history['loss'][0]\n",
    "            epoch_accuracy += batch_history.history['accuracy'][0]\n",
    "            batch_count += 1\n",
    "\n",
    "            clf_probabilities = model_1.predict(x_batch)\n",
    "            threshold = calculate_threshold(clf_probabilities, y_batch)\n",
    "            rewards = calculate_rewards(clf_probabilities, y_batch, threshold)\n",
    "            agent.store_transition(x_batch.numpy(), actions, rewards)\n",
    "            agent.learn()\n",
    "            # break\n",
    "        first_iteration = True\n",
    "        epoch_loss /= batch_count\n",
    "        epoch_accuracy /= batch_count\n",
    "        history['epoch_loss'].append(epoch_loss)\n",
    "        history['epoch_accuracy'].append(epoch_accuracy)\n",
    "        print(f\"Epoch {epoch+1}: Loss = {epoch_loss}, Accuracy = {epoch_accuracy}\")\n",
    "\n",
    "        # early stopping condition\n",
    "        # if epoch > 0 and (history['epoch_accuracy'][-1] - history['epoch_accuracy'][-2]) < min_delta:\n",
    "        #     print(\"Early stopping triggered.\")\n",
    "        #     break\n",
    "\n",
    "        probabilities = model_1.predict(x_test)  # Ensure this is the probability of the positive class\n",
    "        roc_auc = roc_auc_score(y_true=y_test, y_score=probabilities)\n",
    "        history['ROC_AUC'].append(roc_auc)\n",
    "        # Predict probabilities for the positive class\n",
    "        # probabilities = model_1.predict(x_test)\n",
    "        precision, recall, _ = precision_recall_curve(y_true=y_test, probas_pred=probabilities)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        history['PR_AUC'].append(pr_auc)\n",
    "        # predictions = (model_1.predict(x_test) > 0.5).astype(int)\n",
    "        predictions = (probabilities > 0.5).astype(int)\n",
    "        accuracy = accuracy_score(y_true=y_test, y_pred=predictions)\n",
    "        history['accuracy'].append(pr_auc)\n",
    "\n",
    "        recall_value = recall_score(y_true=y_test, y_pred=predictions)\n",
    "        history['recall'].append(recall_value)\n",
    "\n",
    "        # Calculate F1 score\n",
    "        f1 = f1_score(y_true=y_test, y_pred=predictions)\n",
    "        history['f1'].append(f1)\n",
    "        print(\"ROC AUC Score:\", roc_auc)\n",
    "        print(\"Accuracy Score:\", accuracy)\n",
    "        print(\"Precision-Recall AUC:\", pr_auc)\n",
    "        print(\"Recall:\", recall_value)\n",
    "        print(\"F1 Score:\", f1)\n",
    "        \n",
    "\n",
    "        if epoch % 3 == 0:\n",
    "            print(\"Updating target policy...\")\n",
    "            agent.target_model.set_weights(agent.model.get_weights())\n",
    "\n",
    "\n",
    "train_model(x_train=x_train, y_train=y_train, s=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('history_2.pkl', 'wb') as file:\n",
    "    # Use pickle to dump the dictionary into the file\n",
    "    pickle.dump(history, file)\n",
    "\n",
    "with open('history_2.pkl', 'rb') as file:\n",
    "    # Load the dictionary back from the pickle file\n",
    "    loaded_history = pickle.load(file)\n",
    "\n",
    "# Verify the content\n",
    "print(loaded_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "# Predict probabilities for the positive class\n",
    "probabilities = model_1.predict(x_test)  # Ensure this is the probability of the positive class\n",
    "roc_auc = roc_auc_score(y_true=y_test, y_score=probabilities)\n",
    "print(\"ROC AUC Score:\", roc_auc)\n",
    "\n",
    "# Predict class labels based on a threshold, typically 0.5 for binary classifiers\n",
    "predictions = (model_1.predict(x_test) > 0.5).astype(int)\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=predictions)\n",
    "print(\"Accuracy Score:\", accuracy)\n",
    "\n",
    "# Predict probabilities for the positive class\n",
    "probabilities = model_1.predict(x_test)\n",
    "precision, recall, _ = precision_recall_curve(y_true=y_test, probas_pred=probabilities)\n",
    "pr_auc = auc(recall, precision)\n",
    "print(\"Precision-Recall AUC:\", pr_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_policy_model.save_weights('target_policy_model_2.weights.h5')\n",
    "model_1.save_weights('clf_model_after_IL_2.weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "history = {\n",
    "    'epoch_loss': [],\n",
    "    'epoch_accuracy': [],\n",
    "    'batch_loss': [],\n",
    "    'batch_accuracy': [],\n",
    "    'predictions': [],\n",
    "    'rewards': [],\n",
    "    'thresholds': [],\n",
    "    'ROC_AUC': [],\n",
    "    'accuracy':[],\n",
    "    'PR_AUC':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting epoch losses and accuracies\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['epoch_loss'], label='Loss')\n",
    "plt.title('Epoch Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['epoch_accuracy'], label='Accuracy')\n",
    "plt.title('Epoch Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# You can add more plots for batch-level data, rewards, thresholds, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting epoch losses and accuracies\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['batch_loss'], label='Loss')\n",
    "plt.title('Batch Loss')\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['batch_accuracy'], label='Accuracy')\n",
    "plt.title('Batch Accuracy')\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting epoch losses and accuracies 'ROC_AUC': [],\n",
    "    # 'accuracy':[],\n",
    "    # 'PR_AUC':[]\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history['ROC_AUC'], label='Loss')\n",
    "plt.title('ROC AUC')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('ROC')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history['accuracy'], label='Accuracy')\n",
    "plt.title('Epoch Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history['PR_AUC'], label='Accuracy')\n",
    "plt.title('PR AUC')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('PR@Epoch')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Predictions from the second classifier\n",
    "predictions = target_policy_model.predict(x_test)\n",
    "predicted_classes = (predictions > 0.5).astype(int).flatten()  # Assuming binary classification\n",
    "\n",
    "# Selecting a few images to display\n",
    "indices = np.random.choice(range(len(x_test)), 25, replace=False)  # Randomly select 25 images\n",
    "selected_images = x_test[indices]\n",
    "selected_labels = y_test[indices]\n",
    "selected_predictions = predicted_classes[indices]\n",
    "\n",
    "# Plotting\n",
    "plot_images(selected_images, selected_labels, selected_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    \"\"\"Plot training and validation loss and accuracy.\"\"\"\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(10, 10))\n",
    "    axs[0].plot(history.history['loss'], label='train')\n",
    "    axs[0].plot(history.history['val_loss'], label='validation')\n",
    "    axs[0].set_title('Loss')\n",
    "    axs[0].set_xlabel('Epochs')\n",
    "    axs[0].set_ylabel('Loss')\n",
    "    axs[0].legend()\n",
    "\n",
    "    axs[1].plot(history.history['accuracy'], label='train')\n",
    "    axs[1].plot(history.history['val_accuracy'], label='validation')\n",
    "    axs[1].set_title('Accuracy')\n",
    "    axs[1].set_xlabel('Epochs')\n",
    "    axs[1].set_ylabel('Accuracy')\n",
    "    axs[1].legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Assuming you have stored the history of training your models as `history_1` and `history_2`\n",
    "plot_history(history_1)  # For the first classifier\n",
    "plot_history(history_2)  # For the second classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
