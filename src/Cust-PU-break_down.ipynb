{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# import tensorflow_probability as tfp\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load and preprocess MNIST data\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# x_train = x_train / 255.0\n",
    "# x_test = x_test / 255.0\n",
    "# y_train = y_train % 2  # Convert labels to 0 (even) and 1 (odd) \n",
    "# y_train_original = y_train.copy()  # {original labels} \n",
    "# y_test = y_test % 2\n",
    "# y_test_original = y_test.copy()\n",
    "\n",
    "# # # Mark a subset of positive instances as unlabeled\n",
    "# # positive_indices = np.where(y_train == 1)[0]\n",
    "# # # unlabeled_indices = np.random.choice(positive_indices, size=int(len(positive_indices) * 0.99), replace=False)\n",
    "# # unlabeled_indices = np.random.choice(positive_indices, size=int(len(positive_indices) -300), replace=False)\n",
    "# # y_train[unlabeled_indices] = 0  # Marking unlabeled now y_train is PU dataset\n",
    "\n",
    "\n",
    "# # X = x_train  # Your feature matrix\n",
    "\n",
    "# # # Preparing 's', the binary indicator vector\n",
    "# # # Start by marking all instances as 'unlabeled' (0)\n",
    "# # s = np.zeros_like(y_train)\n",
    "# # # Then, mark the originally positive instances as 'labeled' (1), excluding those you've marked as unlabeled\n",
    "# # s[positive_indices] = 1\n",
    "# # s[unlabeled_indices] = 0 # where s=0 y can be either y=1 or y=0\n",
    "\n",
    "\n",
    "# # Select a random 300 rows where y_train == 1\n",
    "# positive_indices = np.where(y_train == 1)[0]\n",
    "# chosen_indices = np.random.choice(positive_indices, size=300, replace=False)\n",
    "\n",
    "# # Mark the rest of the positive_indices except the chosen 300 as potential targets for unlabeled marking\n",
    "# rest_of_positives = np.setdiff1d(positive_indices, chosen_indices)\n",
    "\n",
    "# # From the rest, select 30% and mark their labels as 0\n",
    "# number_to_mark_unlabeled = int(len(rest_of_positives) * 0.3)\n",
    "# unlabeled_indices = np.random.choice(rest_of_positives, size=number_to_mark_unlabeled, replace=False)\n",
    "# y_train[unlabeled_indices] = 0\n",
    "\n",
    "# # Remove the rest of the rows where y=1 that are not in the chosen 300\n",
    "# indices_to_drop = np.setdiff1d(rest_of_positives, unlabeled_indices)\n",
    "# x_train = np.delete(x_train, indices_to_drop, axis=0)\n",
    "# y_train = np.delete(y_train, indices_to_drop)\n",
    "\n",
    "# print(\"Training labels distribution:\", np.bincount(y_train))\n",
    "# print(\"Training original labels distribution:\", np.bincount(y_train_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels distribution: [38554   300]\n",
      "Training original labels distribution: [38554   300]\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "y_train = y_train % 2  # Convert labels to 0 (even) and 1 (odd) \n",
    "y_test = y_test % 2\n",
    "\n",
    "# Initialize 's' to zeros, meaning initially all are unlabeled\n",
    "s = np.zeros_like(y_train)\n",
    "\n",
    "# Select a random 300 samples where y_train == 1 to be labeled\n",
    "positive_indices = np.where(y_train == 1)[0]\n",
    "chosen_indices = np.random.choice(positive_indices, size=300, replace=False)\n",
    "\n",
    "# Mark these as labeled in 's'\n",
    "s[chosen_indices] = 1\n",
    "\n",
    "# Mark the rest of the positive_indices except the chosen 300 as potential targets for unlabeled marking\n",
    "rest_of_positives = np.setdiff1d(positive_indices, chosen_indices)\n",
    "\n",
    "# From the rest, select 30% and mark their labels as 0 in y_train\n",
    "number_to_mark_unlabeled = int(len(rest_of_positives) * 0.3)\n",
    "unlabeled_indices = np.random.choice(rest_of_positives, size=number_to_mark_unlabeled, replace=False)\n",
    "y_train[unlabeled_indices] = 0\n",
    "\n",
    "# Remove the rest of the positive rows that are not in the chosen 300 and not marked as unlabeled\n",
    "indices_to_drop = np.setdiff1d(rest_of_positives, np.concatenate([chosen_indices, unlabeled_indices]))\n",
    "x_train = np.delete(x_train, indices_to_drop, axis=0)\n",
    "y_train = np.delete(y_train, indices_to_drop)\n",
    "s = np.delete(s, indices_to_drop)\n",
    "\n",
    "print(\"Training labels distribution:\", np.bincount(y_train))\n",
    "print(\"Training original labels distribution:\", np.bincount(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_pu_datasets(x, y, n_labeled, pos_fraction):\n",
    "#     # Select a random 300 rows where y_train == 1\n",
    "#     positive_indices = np.where(y_train == 1)[0]\n",
    "#     chosen_indices = np.random.choice(positive_indices, size=n_labeled, replace=False)\n",
    "\n",
    "#     # Mark the rest of the positive_indices except the chosen 300 as potential targets for unlabeled marking\n",
    "#     rest_of_positives = np.setdiff1d(positive_indices, chosen_indices)\n",
    "\n",
    "#     # From the rest, select 30% and mark their labels as 0\n",
    "#     number_to_mark_unlabeled = int(len(rest_of_positives) * pos_fraction)\n",
    "#     unlabeled_indices = np.random.choice(rest_of_positives, size=number_to_mark_unlabeled, replace=False)\n",
    "#     y_train[unlabeled_indices] = 0\n",
    "\n",
    "#     # Remove the rest of the rows where y=1 that are not in the chosen 300\n",
    "#     indices_to_drop = np.setdiff1d(rest_of_positives, unlabeled_indices)\n",
    "#     x_train = np.delete(x_train, indices_to_drop, axis=0)\n",
    "#     y_train = np.delete(y_train, indices_to_drop)\n",
    "\n",
    "#     return x_train, y_train\n",
    "\n",
    "# # Create datasets as per specifications from the paper\n",
    "# # configs = [(300, 0.3), (500, 0.5), (1000, 0.7)]\n",
    "# configs = [(300, 0.3)]\n",
    "# datasets = [create_pu_datasets(x_train, y_train, n, frac) for n, frac in configs]\n",
    "\n",
    "# for i, (train_x_pu, train_y_pu) in enumerate(datasets):\n",
    "#     print(f\"Configuration {i+1} label distribution: {np.bincount(train_y_pu.astype(int))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay = 2.0\n",
    "model_1 = Sequential([\n",
    "    Conv2D(96, (3, 3), padding='same', input_shape=(28, 28, 1), kernel_regularizer=l2(weight_decay)),\n",
    "    # BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Conv2D(192, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)),\n",
    "    # BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Conv2D(10, (1, 1), padding='same', kernel_regularizer=l2(weight_decay)),\n",
    "    # BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Flatten(),\n",
    "    Dense(100, kernel_regularizer=l2(weight_decay)),\n",
    "    Activation('relu'),\n",
    "    Dense(100, kernel_regularizer=l2(weight_decay)),\n",
    "    Activation('relu'),\n",
    "    Dense(1, kernel_regularizer=l2(weight_decay)),\n",
    "    Activation('sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "model_1.compile(optimizer=Adam(learning_rate=0.00001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history_1 = model_1.fit(x_train, y_train, epochs=5, batch_size=128, validation_split=0.2)\n",
    "model_1.save_weights('clf_model_.weights.h5')\n",
    "# model_1.load_weights('clf_model_.weights.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probablistic outcome of classifer to pre-train policy network\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = model_1.predict(x_train)\n",
    "threshold = min(probabilities[y_train == 1])\n",
    "\n",
    "# Convert probabilities to binary labels based on the threshold\n",
    "predicted_labels = (probabilities >= threshold).astype(int)\n",
    "clf_predicted_labels = predicted_labels.flatten().astype(int)\n",
    "\n",
    "print(\"Classifer predicted labels distribution:\", np.bincount(clf_predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy-Network Model\n",
    "\n",
    "class PolicyGradientNetwork:\n",
    "    def __init__(self):\n",
    "        self.model = self._create_model()\n",
    "    \n",
    "    def _create_model(self):\n",
    "        weight_decay = 0.5\n",
    "        model = Sequential([\n",
    "            Conv2D(96, (3, 3), padding='same', input_shape=(28, 28, 1), kernel_regularizer=l2(weight_decay)),\n",
    "            Activation('relu'),\n",
    "            Conv2D(10, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)),\n",
    "            Activation('relu'),\n",
    "            Flatten(),\n",
    "            Dense(100, kernel_regularizer=l2(weight_decay)),\n",
    "            Activation('relu'),\n",
    "            Dense(100, kernel_regularizer=l2(weight_decay)),  # Additional Dense layer\n",
    "            Activation('relu'),\n",
    "            Dense(1, kernel_regularizer=l2(weight_decay)),  # Softmax output for binary classification\n",
    "            Activation('sigmoid') # Hard labeling\n",
    "        ])\n",
    "        return model\n",
    "    \n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "    \n",
    "\n",
    "policy_network = PolicyGradientNetwork()\n",
    "pn_model = policy_network.get_model()\n",
    "\n",
    "pn_model.compile(optimizer=Adam(learning_rate=0.00001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_2 = pn_model.fit(x_train, clf_predicted_labels, epochs=5, batch_size=128, validation_split=0.2)\n",
    "pn_model.save_weights('pn_model_.weights.h5')\n",
    "# pn_model.load_weights('pn_model_.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = pn_model.predict(x_train)\n",
    "threshold = min(probabilities[y_train == 1])\n",
    "\n",
    "# Convert probabilities to binary labels based on the threshold\n",
    "predicted_labels = (probabilities >= threshold).astype(int)\n",
    "np_predicted_labels = predicted_labels.flatten().astype(int)\n",
    "\n",
    "print(\"Classifer predicted labels distribution:\", np.bincount(np_predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, model, target_model, alpha=0.00001, gamma=0.99):\n",
    "        self.gamma = gamma  # Discount factor\n",
    "        self.lr = alpha  # Learning rate\n",
    "        self.model = model  # Policy model\n",
    "        self.target_model = target_model # target policy model\n",
    "        self.state_memory = []\n",
    "        self.action_memory = []\n",
    "        self.reward_memory = []\n",
    "\n",
    "    def choose_action(self, states, s, threshold=0.5):\n",
    "        # Convert states to float32 tensor within the function\n",
    "        states = tf.convert_to_tensor(states, dtype=tf.float32)\n",
    "        probabilities = self.target_model(states)  # Make sure target model expects float32 input\n",
    "        # action_sampler = tfp.distributions.Bernoulli(probs=probabilities, dtype=tf.float32)\n",
    "        # actions = action_sampler.sample()\n",
    "        # print(f\"probabilities ={probabilities}\")\n",
    "        # actions = tf.cast(tf.random.uniform(tf.shape(probabilities)) < probabilities, tf.int32)\n",
    "\n",
    "        inferred_labels = tf.cast(probabilities > threshold, tf.int32)       \n",
    "        s = tf.reshape(s, tf.shape(inferred_labels))  # Ensuring s is the same shape as inferred_labels\n",
    "        actions = tf.where(s == 1, 1, inferred_labels)\n",
    "        actions = tf.squeeze(actions)  # This should correctly squeeze actions to shape (128,)\n",
    "        return actions.numpy(), probabilities.numpy()\n",
    "\n",
    "\n",
    "    def store_transition(self, states, actions, rewards):\n",
    "        self.state_memory.extend(states)\n",
    "        self.action_memory.extend(actions)\n",
    "        self.reward_memory.extend(rewards)\n",
    "\n",
    "    def learn(self):\n",
    "        actions = np.array(self.action_memory)\n",
    "        rewards = np.array(self.reward_memory)\n",
    "        states = np.array(self.state_memory)\n",
    "\n",
    "        # Calculate discounted rewards\n",
    "        G = np.zeros_like(rewards)\n",
    "        for t in range(len(rewards)):\n",
    "            G_sum = 0\n",
    "            discount = 1\n",
    "            for k in range(t, len(rewards)):\n",
    "                G_sum += rewards[k] * discount\n",
    "                discount *= self.gamma\n",
    "            G[t] = G_sum\n",
    "\n",
    "        # Updating policy\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = 0\n",
    "            for idx, (g, state) in enumerate(zip(G, states)):\n",
    "                state = tf.convert_to_tensor([state], dtype=tf.float32)\n",
    "                probs = self.model(state, training=True)\n",
    "                # action_probs = tfp.distributions.Bernoulli(probs=probs)\n",
    "                # log_prob = action_probs.log_prob(actions[idx])\n",
    "                # loss += -g * tf.reduce_sum(log_prob)\n",
    "                action_probs = tf.where(actions[idx] == 1, probs, 1 - probs)\n",
    "                log_prob = tf.math.log(action_probs)\n",
    "                loss += -g * tf.reduce_sum(log_prob)\n",
    "\n",
    "        gradients = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.model.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
    "\n",
    "        # Clear memory\n",
    "        self.state_memory = []\n",
    "        self.action_memory = []\n",
    "        self.reward_memory = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone policy model for stable target policy\n",
    "target_policy_model = tf.keras.models.clone_model(pn_model)\n",
    "target_policy_model.compile(optimizer=Adam(learning_rate=0.00001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = {\n",
    "    'epoch_loss': [],\n",
    "    'epoch_accuracy': [],\n",
    "    'batch_loss': [],\n",
    "    'batch_accuracy': [],\n",
    "    'predictions': [],\n",
    "    'rewards': [],\n",
    "    'thresholds': [],\n",
    "    'ROC_AUC': [],\n",
    "    'accuracy':[],\n",
    "    'PR_AUC':[]\n",
    "}\n",
    "agent = Agent(pn_model,target_model=target_policy_model, alpha=0.00001, gamma=0.99)\n",
    "# Example parameters\n",
    "n_epochs = 300\n",
    "n_epochs = 10\n",
    "batch_size = 128 # You can adjust the batch size as needed\n",
    "\n",
    "def shuffle_data(x_train, y_train, s):\n",
    "    indices = np.arange(len(x_train))\n",
    "    np.random.shuffle(indices)\n",
    "    return x_train[indices], y_train[indices], s[indices]\n",
    "\n",
    "def create_mini_batches(x_train, y_train, s, batch_size):\n",
    "    for start_idx in range(0, len(x_train) - batch_size + 1, batch_size):\n",
    "        excerpt = slice(start_idx, start_idx + batch_size)\n",
    "        yield x_train[excerpt], y_train[excerpt], s[excerpt]\n",
    "\n",
    "def calculate_threshold(clf_probabilities, y_batch):\n",
    "    # Identify indices of positive examples\n",
    "    positive_indices = (y_batch == 1)\n",
    "    \n",
    "    # Calculate threshmin from positive examples\n",
    "    if np.any(positive_indices):\n",
    "        threshmin = np.min(clf_probabilities[positive_indices])\n",
    "    else:\n",
    "        threshmin = 0  # Default value if no positive examples are present\n",
    "\n",
    "    # Identify U0 - samples with predictions >= threshmin\n",
    "    U0_indices = (clf_probabilities >= threshmin)\n",
    "    \n",
    "    # Calculate the final threshold using Equation 5\n",
    "    if np.any(U0_indices):\n",
    "        threshold = np.mean(clf_probabilities[U0_indices])\n",
    "    else:\n",
    "        threshold = threshmin  # Use threshmin if no samples meet the U0 criteria\n",
    "\n",
    "    return threshold\n",
    "\n",
    "def calculate_rewards(clf_probabilities, y_batch, threshold):\n",
    "    # Reward calculation needs to consider whether predictions meet a certain threshold\n",
    "    # Positive examples above threshold or negative examples below threshold get positive rewards\n",
    "    rewards = []\n",
    "    for prob, actual in zip(clf_probabilities.flatten(), y_batch):\n",
    "        if actual == 1 or (actual == 0 and prob >= threshold):\n",
    "            reward = prob  # Reward is the probability itself if conditions are met\n",
    "        else:\n",
    "            reward = 1 - prob  # Otherwise, reward is the complement of the probability\n",
    "        rewards.append(reward)\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train, y_train, s, epochs=300, batch_size=128, min_delta=0.0001, patience=10):\n",
    "    x_train = x_train.astype('float32')\n",
    "    y_train = y_train.astype('float32')\n",
    "    s = s.astype('float32')\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train, s))\n",
    "    dataset = dataset.shuffle(buffer_size=len(x_train)).batch(batch_size)\n",
    "\n",
    "    # early_stopping = EarlyStopping(monitor='val_accuracy', patience=patience, min_delta=min_delta, mode='max', restore_best_weights=True, verbose=1)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        epoch_loss = 0\n",
    "        epoch_accuracy = 0\n",
    "        batch_count = 0\n",
    "        # first_iteration = True\n",
    "        # threshold_pass = 0.5\n",
    "        threshold = 0.5\n",
    "        for x_batch, y_batch, s_batch in dataset:\n",
    "            # Get actions and probabilities for the entire batch\n",
    "            actions, probabilities = agent.choose_action(x_batch, s_batch, threshold=threshold)\n",
    "\n",
    "            # Fit the model on the current batch and update history\n",
    "            batch_history = model_1.fit(x_batch, actions, epochs=1, batch_size=len(x_batch), validation_split=0.2, verbose=0)\n",
    "            history['batch_loss'].append(batch_history.history['loss'][0])\n",
    "            history['batch_accuracy'].append(batch_history.history['accuracy'][0])\n",
    "            epoch_loss += batch_history.history['loss'][0]\n",
    "            epoch_accuracy += batch_history.history['accuracy'][0]\n",
    "            batch_count += 1\n",
    "\n",
    "            clf_probabilities = model_1.predict(x_batch)\n",
    "            threshold = calculate_threshold(clf_probabilities, y_batch)\n",
    "            rewards = calculate_rewards(clf_probabilities, y_batch, threshold)\n",
    "            agent.store_transition(x_batch.numpy(), actions, rewards)\n",
    "            agent.learn()\n",
    "            # break\n",
    "        first_iteration = True\n",
    "        epoch_loss /= batch_count\n",
    "        epoch_accuracy /= batch_count\n",
    "        history['epoch_loss'].append(epoch_loss)\n",
    "        history['epoch_accuracy'].append(epoch_accuracy)\n",
    "        print(f\"Epoch {epoch+1}: Loss = {epoch_loss}, Accuracy = {epoch_accuracy}\")\n",
    "\n",
    "        # early stopping condition\n",
    "        # if epoch > 0 and (history['epoch_accuracy'][-1] - history['epoch_accuracy'][-2]) < min_delta:\n",
    "        #     print(\"Early stopping triggered.\")\n",
    "        #     break\n",
    "\n",
    "        probabilities = model_1.predict(x_test)  # Ensure this is the probability of the positive class\n",
    "        roc_auc = roc_auc_score(y_true=y_test, y_score=probabilities)\n",
    "        history['ROC_AUC'].append(roc_auc)\n",
    "        # Predict probabilities for the positive class\n",
    "        # probabilities = model_1.predict(x_test)\n",
    "        precision, recall, _ = precision_recall_curve(y_true=y_test, probas_pred=probabilities)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        history['PR_AUC'].append(pr_auc)\n",
    "        # predictions = (model_1.predict(x_test) > 0.5).astype(int)\n",
    "        predictions = (probabilities > 0.5).astype(int)\n",
    "        accuracy = accuracy_score(y_true=y_test, y_pred=predictions)\n",
    "        history['accuracy'].append(pr_auc)\n",
    "        print(\"ROC AUC Score:\", roc_auc)\n",
    "        print(\"Accuracy Score:\", accuracy)\n",
    "        print(\"Precision-Recall AUC:\", pr_auc)\n",
    "        \n",
    "\n",
    "        if epoch % 3 == 0:\n",
    "            print(\"Updating target policy...\")\n",
    "            agent.target_model.set_weights(agent.model.get_weights())\n",
    "\n",
    "\n",
    "train_model(x_train=x_train, y_train=y_train, s=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('history.pkl', 'wb') as file:\n",
    "    # Use pickle to dump the dictionary into the file\n",
    "    pickle.dump(history, file)\n",
    "\n",
    "with open('history.pkl', 'rb') as file:\n",
    "    # Load the dictionary back from the pickle file\n",
    "    loaded_history = pickle.load(file)\n",
    "\n",
    "# Verify the content\n",
    "print(loaded_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "# Predict probabilities for the positive class\n",
    "probabilities = model_1.predict(x_test)  # Ensure this is the probability of the positive class\n",
    "roc_auc = roc_auc_score(y_true=y_test, y_score=probabilities)\n",
    "print(\"ROC AUC Score:\", roc_auc)\n",
    "\n",
    "# Predict class labels based on a threshold, typically 0.5 for binary classifiers\n",
    "predictions = (model_1.predict(x_test) > 0.5).astype(int)\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=predictions)\n",
    "print(\"Accuracy Score:\", accuracy)\n",
    "\n",
    "# Predict probabilities for the positive class\n",
    "probabilities = model_1.predict(x_test)\n",
    "precision, recall, _ = precision_recall_curve(y_true=y_test, probas_pred=probabilities)\n",
    "pr_auc = auc(recall, precision)\n",
    "print(\"Precision-Recall AUC:\", pr_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_policy_model.save_weights('target_policy_model_.weights.h5')\n",
    "model_1.save_weights('clf_model_after_IL.weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "history = {\n",
    "    'epoch_loss': [],\n",
    "    'epoch_accuracy': [],\n",
    "    'batch_loss': [],\n",
    "    'batch_accuracy': [],\n",
    "    'predictions': [],\n",
    "    'rewards': [],\n",
    "    'thresholds': [],\n",
    "    'ROC_AUC': [],\n",
    "    'accuracy':[],\n",
    "    'PR_AUC':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting epoch losses and accuracies\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['epoch_loss'], label='Loss')\n",
    "plt.title('Epoch Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['epoch_accuracy'], label='Accuracy')\n",
    "plt.title('Epoch Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# You can add more plots for batch-level data, rewards, thresholds, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting epoch losses and accuracies\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['batch_loss'], label='Loss')\n",
    "plt.title('Batch Loss')\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['batch_accuracy'], label='Accuracy')\n",
    "plt.title('Batch Accuracy')\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting epoch losses and accuracies 'ROC_AUC': [],\n",
    "    # 'accuracy':[],\n",
    "    # 'PR_AUC':[]\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history['ROC_AUC'], label='Loss')\n",
    "plt.title('ROC AUC')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('ROC')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history['accuracy'], label='Accuracy')\n",
    "plt.title('Epoch Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history['PR_AUC'], label='Accuracy')\n",
    "plt.title('PR AUC')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('PR@Epoch')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_images(images, labels, predictions=None):\n",
    "    \"\"\"Plot images with their labels. Show predictions if provided.\"\"\"\n",
    "    n = images.shape[0]\n",
    "    sqrt_val = int(np.ceil(np.sqrt(n)))\n",
    "    fig, axes = plt.subplots(sqrt_val, sqrt_val, figsize=(10, 10))\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i >= n:\n",
    "            break\n",
    "        ax.imshow(images[i], cmap='binary')\n",
    "        \n",
    "        if predictions is not None:\n",
    "            ax.set_title(f\"True: {labels[i]}\\nPred: {predictions[i]}\")\n",
    "        else:\n",
    "            ax.set_title(f\"Label: {labels[i]}\")\n",
    "        \n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    plt.show()\n",
    "\n",
    "# Predictions from the second classifier\n",
    "predictions = model_2.predict(X_test_reshaped)\n",
    "predicted_classes = (predictions > 0.5).astype(int).flatten()  # Assuming binary classification\n",
    "\n",
    "# Selecting a few images to display\n",
    "indices = np.random.choice(range(len(x_test)), 25, replace=False)  # Randomly select 25 images\n",
    "selected_images = x_test[indices]\n",
    "selected_labels = y_test[indices]\n",
    "selected_predictions = predicted_classes[indices]\n",
    "\n",
    "# Plotting\n",
    "plot_images(selected_images, selected_labels, selected_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    \"\"\"Plot training and validation loss and accuracy.\"\"\"\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(10, 10))\n",
    "    axs[0].plot(history.history['loss'], label='train')\n",
    "    axs[0].plot(history.history['val_loss'], label='validation')\n",
    "    axs[0].set_title('Loss')\n",
    "    axs[0].set_xlabel('Epochs')\n",
    "    axs[0].set_ylabel('Loss')\n",
    "    axs[0].legend()\n",
    "\n",
    "    axs[1].plot(history.history['accuracy'], label='train')\n",
    "    axs[1].plot(history.history['val_accuracy'], label='validation')\n",
    "    axs[1].set_title('Accuracy')\n",
    "    axs[1].set_xlabel('Epochs')\n",
    "    axs[1].set_ylabel('Accuracy')\n",
    "    axs[1].legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Assuming you have stored the history of training your models as `history_1` and `history_2`\n",
    "plot_history(history_1)  # For the first classifier\n",
    "plot_history(history_2)  # For the second classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_c_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
